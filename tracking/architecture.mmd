---
config:
  theme: neo
  look: handDrawn
  layout: elk
---
flowchart TD
 subgraph subGraph0["Batch Processing Pipeline (Orchestrated by ğŸ› ï¸ track.py)"]
    direction LR
        raw_video@{ label: "<span style='font-size:1.5em'>ğŸ¥</span><br>Input Video/.mp4" }
        vp@{ label: "<span style='font-size:1.5em'>ğŸï¸</span><br>video_processing.py" }
        ap@{ label: "<span style='font-size:1.5em'>ğŸ”Š</span><br>audio_processing.py" }
        ld@{ label: "<span style='font-size:1.5em'>ğŸ”—</span><br>link_data.py" }
        gp@{ label: "<span style='font-size:1.5em'>ğŸ“ˆ</span><br>graphify.py" }
        vec_util@{ label: "<span style='font-size:1.5em'>ğŸ§¬</span><br>vectorize.py<br>(Utility)" }
        minio_batch@{ label: "<span style='font-size:1.5em'>ğŸ“¦</span><br>MinIO<br>(Frames, Crops)" }
        qdrant_batch@{ label: "<span style='font-size:1.5em'>ğŸ’¾</span><br>Qdrant<br>(Visual/Audio Vectors)" }
        neo4j_batch@{ label: "<span style='font-size:1.5em'>ğŸ•¸ï¸</span><br>Neo4j<br>(Graph Data)" }
        fs_batch@{ label: "<span style='font-size:1.5em'>ğŸ“‚</span><br>File System<br>(JSON Logs, Temp Media)" }
  end
 subgraph subGraph1["Interactive Inference Pipeline (infer.py)"]
    direction LR
        user_query@{ label: "<span style='font-size:1.5em'>ğŸ’¬</span><br>User Text Query" }
        infer_py@{ label: "<span style='font-size:1.5em'>ğŸ§©</span><br>infer.py" }
        infer_embedding_model@{ label: "<span style='font-size:1.5em'>ğŸ”¢</span><br>Embedding Model<br>(via vectorize.py)" }
        openai_api@{ label: "<span style='font-size:1.5em'>ğŸ¤–</span><br>OpenAI API" }
        minio_infer@{ label: "<span style='font-size:1.5em'>ğŸ“¦</span><br>MinIO" }
        qdrant_infer@{ label: "<span style='font-size:1.5em'>ğŸ’¾</span><br>Qdrant" }
        neo4j_infer@{ label: "<span style='font-size:1.5em'>ğŸ•¸ï¸</span><br>Neo4j" }
        assistant_response@{ label: "<span style='font-size:1.5em'>âœ‰ï¸</span><br>Assistant Response" }
  end
 subgraph subGraph2["Orchestration & Config"]
        track_py@{ label: "<span style='font-size:1.5em'>ğŸ› ï¸</span><br>track.py" }
        docker_compose@{ label: "<span style='font-size:1.5em'>ğŸ³</span><br>docker-compose.yml" }
  end

    raw_video --> vp
    raw_video --> ap

    vp -- Uses --> vec_util
    ap -- Uses --> vec_util
    infer_py -- Uses --> vec_util

    vec_util -- Stores Visual/Audio Embeddings --> qdrant_batch
    vec_util -- Stores Frame/Crop Images --> minio_batch

    vp -- "initial_dataset.json" --> ld
    vp -- Visual Embeddings/Metadata (via vec_util) --> qdrant_batch
    vp -- Frame/Entity Images (via vec_util) --> minio_batch
    
    ap -- "*_audio_segments.json" --> ld
    ap -- Audio Transcript Embeddings (via vec_util) --> qdrant_batch
    
    ld -- "enriched_dataset.json" --> gp
    ld -- Updates Payloads --> qdrant_batch
    
    gp -- Graph Data --> neo4j_batch
    
    fs_batch <--> vp 
    fs_batch <--> ap 
    fs_batch <--> ld 
    fs_batch <--> gp
    fs_batch <--> track_py

    user_query --> infer_py
    infer_py --> infer_embedding_model
    infer_py --> assistant_response
    
    infer_py -- Search Visual/Audio Vectors --> qdrant_infer
    qdrant_infer -- Vector IDs/Payloads --> infer_py
    
    infer_py -- Retrieve Images (by MinIO ID from Qdrant payload) --> minio_infer
    minio_infer -- Image Data --> infer_py
    
    qdrant_infer -- Transcript Data (from payload) --> infer_py 
    
    infer_py -- Query Graph --> neo4j_infer
    neo4j_infer -- Graph Context --> infer_py
    
    infer_py -- Multimodal Prompt --> openai_api
    openai_api -- LLM Response --> infer_py
    
    track_py -- Orchestrates --> vp
    track_py -- Orchestrates --> ap
    track_py -- Orchestrates --> ld
    track_py -- Orchestrates --> gp
    track_py -- Calls Reinitialization --> vec_util

    classDef batch fill:#D6EAF8,stroke:#3498DB,stroke-width:2px,color:black,font-weight:bold
    classDef infer fill:#D5F5E3,stroke:#2ECC71,stroke-width:2px,color:black,font-weight:bold
    classDef datastore fill:#FCF3CF,stroke:#F1C40F,stroke-width:2px,color:black,font-weight:bold
    classDef utility fill:#FDEBD0,stroke:#E67E22,stroke-width:2px,color:black,font-weight:bold
    classDef external fill:#EBDEF0,stroke:#8E44AD,stroke-width:2px,color:black,font-weight:bold
    classDef orchestrator fill:#FADBD8,stroke:#C0392B,stroke-width:2px,color:black,font-weight:bold

    class raw_video,vp,ap,ld,gp,fs_batch batch;
    class vec_util utility;
    class minio_batch,qdrant_batch,neo4j_batch datastore;
    class user_query,infer_py,infer_embedding_model,assistant_response infer;
    class openai_api external;
    class minio_infer,qdrant_infer,neo4j_infer datastore;
    class track_py orchestrator;
    class docker_compose orchestrator;
